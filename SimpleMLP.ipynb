{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ee14dcb-60f3-4eb4-b279-278f056c0abd",
   "metadata": {},
   "source": [
    "<p>Here, we try to simplify part of the code by implementing a simple and multi-layered neural network to have mentality.</p>\n",
    "\n",
    "* Train\n",
    "* Test\n",
    "* Save Weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ab6d7f-1b57-4e1d-accd-c79ef840a391",
   "metadata": {},
   "source": [
    "##### In all stages, we will use the existing dataset called </br>```train.csv``` for train network </br> ```test.csv``` for test and validate \n",
    "##### custom MNIST dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8906838-1367-4594-ba4c-c3d27e17af09",
   "metadata": {},
   "source": [
    "#### imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c669192-2547-484c-a42a-c2266009df53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # matrix cals\n",
    "import pandas as pd # data analys\n",
    "from matplotlib import pyplot as plt # data Visualing\n",
    "import json # for save json format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5fb21cd-2490-4e26-a820-26255fc2e283",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('train.csv') # load Train DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1614054-6ded-4f8c-a0e7-6c4044fa4d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = np.array(dataset)\n",
    "np.random.shuffle(dataset) # shuffle before splitting into dev and training sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5e35b58-9170-4376-a6d8-995a0143e95d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000, 785)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ae214f-7718-4dcd-b32a-323e4737d53a",
   "metadata": {},
   "source": [
    "#### split train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e24dc43-2b0f-4f7e-8257-56d3a41f4b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "tests = dataset[:1000].T # transpose Matrix | 1000 image test (785 row and 0-999 col)\n",
    "testY = tests[0] # split labels\n",
    "testX = tests[1:] # choise image data\n",
    "testX = testX / 255. # normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1210cfd8-9391-441c-8933-79b13fc6a559",
   "metadata": {},
   "outputs": [],
   "source": [
    "trains = dataset[1000:].T # transpose Matrix | learning 41000 image (1000 to 42000 col)\n",
    "trainY = trains[0] # choise label\n",
    "trainX = trains[1:] # choise image data\n",
    "trainX = trainX / 255.  # normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "14ef6663-e303-42ed-afb0-8da50aff9d09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((784, 1000), (784, 41000))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(testX.shape, trainX.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a7a557-09c1-4938-8a37-03e7cf20181a",
   "metadata": {},
   "source": [
    "### MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ffa008f4-7a4e-41fd-8d40-f4dfc1e9ce20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_params():\n",
    "    # each row = node\n",
    "    W1 = np.random.rand(100, 784) - 0.5  # 100 row and 784 col\n",
    "    b1 = np.random.rand(100, 1) - 0.5  # 100 row and 1 col\n",
    "    W2 = np.random.rand(10, 100) - 0.5  # 10 row and 100 col\n",
    "    b2 = np.random.rand(10, 1) - 0.5  # 10 row and 1 col\n",
    "    return W1, b1, W2, b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "72bdd77f-5527-4802-894a-3dd426a2da8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReLU(Z):\n",
    "    return np.maximum(Z, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "05de9ab0-c940-4dc1-91f3-51a3c4b17b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(Z):\n",
    "    return  np.exp(Z) / sum(np.exp(Z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a4c20af4-6284-4244-957c-21ae2a3621be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReLU_deriv(Z):\n",
    "    return Z > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "22f82f87-4b3c-4c08-a579-427861e92d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(Y):\n",
    "    one_hot_Y = np.zeros((Y.size, Y.max() + 1))\n",
    "    one_hot_Y[np.arange(Y.size), Y] = 1\n",
    "    return one_hot_Y.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e21026db-69e9-40cd-9777-d2cc584a65de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_prop(Z1, A1, Z2, A2, W1, W2, X, Y):\n",
    "    one_hot_Y = one_hot(Y)\n",
    "    dZ2 = A2 - one_hot_Y\n",
    "    dW2 = 1 / dataset.shape[0] * dZ2.dot(A1.T)\n",
    "    db2 = 1 / dataset.shape[0] * np.sum(dZ2)\n",
    "    dZ1 = W2.T.dot(dZ2) * ReLU_deriv(Z1)\n",
    "    dW1 = 1 / dataset.shape[0] * dZ1.dot(X.T)\n",
    "    db1 = 1 / dataset.shape[0] * np.sum(dZ1)\n",
    "    return dW1, db1, dW2, db2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f0118fbc-4eed-4bee-a898-5cb03a72e4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_params(W1, b1, W2, b2, dW1, db1, dW2, db2, learningRate):\n",
    "    W1 = W1 - learningRate * dW1\n",
    "    b1 = b1 - learningRate * db1    \n",
    "    W2 = W2 - learningRate * dW2  \n",
    "    b2 = b2 - learningRate * db2    \n",
    "    return W1, b1, W2, b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ce51670f-759d-428b-a21d-0e34a9e44809",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(predictions, Y):\n",
    "    return np.sum(predictions == Y) / Y.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b33a7f7d-1e10-40ec-bf01-b8384646e2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(A2):\n",
    "    return np.argmax(A2, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dacf7826-bf6f-472b-9a37-1a209728434c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_prop(W1, b1, W2, b2, X):\n",
    "    Z1 = W1.dot(X) + b1\n",
    "    A1 = ReLU(Z1)\n",
    "    Z2 = W2.dot(A1) + b2\n",
    "    A2 = softmax(Z2)\n",
    "    return Z1, A1, Z2, A2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "89e0d1d2-fa4c-4673-aeac-6d03c252cf61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(X, Y, learningRate, epoch):\n",
    "    W1, b1, W2, b2 = init_params()\n",
    "    for i in range(epoch):\n",
    "        Z1, A1, Z2, A2 = forward_prop(W1, b1, W2, b2, X)\n",
    "        dW1, db1, dW2, db2 = backward_prop(Z1, A1, Z2, A2, W1, W2, X, Y)\n",
    "        W1, b1, W2, b2 = update_params(W1, b1, W2, b2, dW1, db1, dW2, db2, learningRate)\n",
    "        if i % 10 == 0:\n",
    "            print(\"epoch: \", i)\n",
    "            predictions = get_predictions(A2)\n",
    "            print(\"Acrcy: \",get_accuracy(predictions, Y))\n",
    "    return W1, b1, W2, b2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88ce7acf-4bc1-4228-847f-b48af043bd93",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "38199cf6-b33a-4c6b-ac9d-f0c3776670b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "463c009e-4942-4030-a2c7-c4ba1a3621c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0\n",
      "Acrcy:  0.12851219512195122\n",
      "epoch:  10\n",
      "Acrcy:  0.433\n",
      "epoch:  20\n",
      "Acrcy:  0.5757560975609756\n",
      "epoch:  30\n",
      "Acrcy:  0.6496829268292683\n",
      "epoch:  40\n",
      "Acrcy:  0.695390243902439\n",
      "epoch:  50\n",
      "Acrcy:  0.724780487804878\n",
      "epoch:  60\n",
      "Acrcy:  0.7478292682926829\n"
     ]
    }
   ],
   "source": [
    "W1, b1, W2, b2 = gradient_descent(trainX, trainY, 0.10, epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca79e82-ad4d-45a9-9c12-d23f0f0502c1",
   "metadata": {},
   "source": [
    "### predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e7e046-3c94-474e-b2a5-92dcc001ea1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_predictions(X, W1, b1, W2, b2):\n",
    "    _, _, _, A2 = forward_prop(W1, b1, W2, b2, X)\n",
    "    predictions = get_predictions(A2)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8941532b-a1c7-42d7-8ccb-53e8d2595567",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_prediction(index, W1, b1, W2, b2):\n",
    "    current_image = trainX[:, index, None]\n",
    "    prediction = make_predictions(trainX[:, index, None], W1, b1, W2, b2)\n",
    "    label = trainY[index]\n",
    "    print(\"Prediction: \", prediction)\n",
    "    print(\"Label: \", label)\n",
    "    current_image = current_image.reshape((28, 28)) * 255\n",
    "    plt.gray()\n",
    "    plt.imshow(current_image, interpolation='nearest')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df040373-a471-4901-bdc9-5fbcb3f23eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prediction(0, W1, b1, W2, b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d5cda3-d3e9-4953-bff2-105eb2a11ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prediction(3, W1, b1, W2, b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6480bcb-7016-43d9-aee2-3f1ad7daa8f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prediction(2, W1, b1, W2, b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea700cb-627d-427b-8bb9-5db7138f8174",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prediction(4, W1, b1, W2, b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df46525-cc00-443e-b99b-fa2b786d9f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_accuracy(make_predictions(testX, W1, b1, W2, b2), testY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0880633-d5fe-4107-a592-f5109600394f",
   "metadata": {},
   "source": [
    "### save Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a76833e-101e-434a-84ba-2073133f9aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = {\n",
    "\t\"w1\": W1.tolist(),\n",
    "\t\"w2\": W2.tolist(),\n",
    "    \"b1\": b1.tolist(),\n",
    "\t\"b2\": b2.tolist()\n",
    "}\n",
    "json_object = json.dumps(res, indent=4)\n",
    "with open(\"wgts\\simpleMLPWghts.json\", \"w\") as outfile:\n",
    "\toutfile.write(json_object)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
